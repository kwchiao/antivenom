{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 39009,
     "status": "ok",
     "timestamp": 1560058826783,
     "user": {
      "displayName": "Kuo-Wei Michael Chiao",
      "photoUrl": "",
      "userId": "12454134270468782567"
     },
     "user_tz": 420
    },
    "id": "JZy0Ly3CvvU7",
    "outputId": "73c84353-52cd-49f9-fbdb-23adab6b06a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LW5rbUD8v9Vj"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "path = '/content/gdrive/Team Drives/cs273p project'\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2464,
     "status": "ok",
     "timestamp": 1560059328308,
     "user": {
      "displayName": "Kuo-Wei Michael Chiao",
      "photoUrl": "",
      "userId": "12454134270468782567"
     },
     "user_tz": 420
    },
    "id": "PnADFufJwGjM",
    "outputId": "d92de0a4-6092-4fad-dc4d-0cf70903b18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITSC4rO2yMHj"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def saveobj(save_list, filename):\n",
    "    with open(path + '/' + filename, 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "        pickle.dump(save_list, f)\n",
    "        \n",
    "# restore object        \n",
    "def loadobj(filename):\n",
    "    with open(path + '/' + filename, 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "        li = pickle.load(f)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3B16XRowgeo"
   },
   "outputs": [],
   "source": [
    "import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldQ4_MPgwYYI"
   },
   "outputs": [],
   "source": [
    "train_file_path = path + '/data/train.csv'\n",
    "test_file_path = path + '/data/test.csv'\n",
    "test_label_file_path = path + '/data/test_labels.csv'\n",
    "\n",
    "train_df, valid_df = data_loader.load_train_data(train_file_path, valid_rate=0.1, is_df=True)\n",
    "test_df = data_loader.load_test_data(test_file_path, test_label_file_path, is_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdyNulzhwmzq"
   },
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1560059385533,
     "user": {
      "displayName": "Kuo-Wei Michael Chiao",
      "photoUrl": "",
      "userId": "12454134270468782567"
     },
     "user_tz": 420
    },
    "id": "eP99535gwoYY",
    "outputId": "7c6bd15e-5f37-4109-c107-8a5cd6aa2a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape:  (143645, 8)\n",
      "valid_df.shape:  (15926, 8)\n",
      "test_df.shape:  (63978, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_df.shape: \", train_df.shape)\n",
    "print(\"valid_df.shape: \", valid_df.shape)\n",
    "print(\"test_df.shape: \", test_df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVaLUp_Cwp23"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Text Cleaning\n",
    "1. Lowercasing\n",
    "2. Remove punctuation\n",
    "3. Remove marginal white space or newline\n",
    "      - strip left and right\n",
    "      - \\n\n",
    "4. Remove stop words\n",
    "5. Lemmatization\n",
    "\n",
    "### After clean up, remove empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZD8tv_twrai"
   },
   "outputs": [],
   "source": [
    "lemtzr = WordNetLemmatizer() \n",
    "\n",
    "def dataCleaning(row):\n",
    "  txt = row['comment_text']\n",
    "  txt = txt.lower() \n",
    "  \n",
    "  ## expand contraction \n",
    "  ## code from https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "  txt = re.sub(r\"won\\'t\", \"will not\", txt)\n",
    "  txt = re.sub(r\"can\\'t\", \"can not\", txt)\n",
    "  txt = re.sub(r\"n\\'t\", \" not\", txt)\n",
    "  txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "  txt = re.sub(r\"\\'s\", \" is\", txt)\n",
    "  txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "  txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "  txt = re.sub(r\"\\'t\", \" not\", txt)\n",
    "  txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "  txt = re.sub(r\"\\'m\", \" am\", txt)\n",
    "  \n",
    "  txt = re.sub('\\W', ' ', txt)                                                  # remove non word characters\n",
    "  txt = re.sub('\\s+', ' ', txt)                                                 # remove white spaces\n",
    "  \n",
    "  txt = ' '.join([lemtzr.lemmatize(wrd) for wrd in txt.split(' ')])             # lemmatize\n",
    "  return txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EKTCPUmwxNT"
   },
   "outputs": [],
   "source": [
    "train_df['filt_comment'] = train_df.apply(dataCleaning, axis = 1)\n",
    "valid_df['filt_comment'] = valid_df.apply(dataCleaning, axis = 1)\n",
    "test_df['filt_comment'] = test_df.apply(dataCleaning, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LeElQ_ryw3Dt"
   },
   "outputs": [],
   "source": [
    "saveobj([train_df, valid_df, test_df], 'data/filtered_comment_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AYE97HE6yt_g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
